--- crash-5.0.0/x86_64.c.orig
+++ crash-5.0.0/x86_64.c
@@ -83,6 +83,7 @@ static void x86_64_irq_eframe_link_init(
 static void x86_64_framepointer_init(void);
 static void x86_64_xendump_phys_base(void);
 static int x86_64_xendump_p2m_create(struct xendump_data *);
+static int x86_64_pvops_xendump_p2m_create(struct xendump_data *);
 static char *x86_64_xendump_load_page(ulong, struct xendump_data *);
 static int x86_64_xendump_page_index(ulong, struct xendump_data *);
 static int x86_64_xen_kdump_p2m_create(struct xen_kdump_data *);
@@ -375,6 +376,7 @@ x86_64_init(int when)
 				switch (machdep->flags & VM_FLAGS)
 				{
 				case VM_XEN: 
+				case VM_2_6_11:
                         		machdep->uvtop = x86_64_uvtop_level4_xen_wpt;
 					break;
 				case VM_XEN_RHEL4:
@@ -506,7 +508,9 @@ x86_64_dump_machdep_table(ulong arg)
         fprintf(fp, "       verify_paddr: generic_verify_paddr()\n");
         fprintf(fp, "    init_kernel_pgd: x86_64_init_kernel_pgd()\n");
         fprintf(fp, "clear_machdep_cache: x86_64_clear_machdep_cache()\n");
-	fprintf(fp, " xendump_p2m_create: x86_64_xendump_p2m_create()\n");
+	fprintf(fp, " xendump_p2m_create: %s\n", PVOPS_XEN() ?
+		"x86_64_pvops_xendump_p2m_create()" :
+		"x86_64_xendump_p2m_create()");
 	fprintf(fp, "   get_xendump_regs: x86_64_get_xendump_regs()\n");
 	fprintf(fp, " xendump_panic_task: x86_64_xendump_panic_task()\n");
 	fprintf(fp, "xen_kdump_p2m_create: x86_64_xen_kdump_p2m_create()\n");
@@ -5362,7 +5366,8 @@ x86_64_calc_phys_base(void)
 			}
 		}
 
-		x86_64_xendump_phys_base();
+		if (xd->xc_core.header.xch_magic == XC_CORE_MAGIC_HVM)
+			x86_64_xendump_phys_base();
 	}
 }
 
@@ -5417,6 +5422,13 @@ x86_64_xendump_p2m_create(struct xendump
 	ulong *up;
 	off_t offset; 
 
+	/*
+	 *  Check for pvops Xen kernel before presuming it's HVM.
+	 */
+	if (symbol_exists("pv_init_ops") && symbol_exists("xen_patch") &&
+	    (xd->xc_core.header.xch_magic == XC_CORE_MAGIC))
+		return x86_64_pvops_xendump_p2m_create(xd);
+
         if (!symbol_exists("phys_to_machine_mapping")) {
                 xd->flags |= XC_CORE_NO_P2M;
                 return TRUE;
@@ -5459,7 +5471,7 @@ x86_64_xendump_p2m_create(struct xendump
 
 	up = (ulong *)(xd->page + PAGEOFFSET(kvaddr));
 	if (CRASHDEBUG(1))
-		fprintf(xd->ofp, "end_pfn: %lx\n", *up);
+		fprintf(xd->ofp, "end pfn: %lx\n", *up);
 
 	xd->xc_core.p2m_frames = (*up/(PAGESIZE()/sizeof(ulong))) +
                 ((*up%(PAGESIZE()/sizeof(ulong))) ? 1 : 0);
@@ -5491,6 +5503,102 @@ x86_64_xendump_p2m_create(struct xendump
 	return TRUE;
 }
 
+static int 
+x86_64_pvops_xendump_p2m_create(struct xendump_data *xd)
+{
+	int i, p, idx;
+	ulong mfn, kvaddr, ctrlreg[8], ctrlreg_offset;
+	ulong *up;
+	off_t offset; 
+	struct syment *sp;
+
+	if ((ctrlreg_offset = MEMBER_OFFSET("vcpu_guest_context", "ctrlreg")) ==
+	     INVALID_OFFSET)
+		error(FATAL, 
+		    "cannot determine vcpu_guest_context.ctrlreg offset\n");
+	else if (CRASHDEBUG(1))
+		fprintf(xd->ofp, 
+		    "MEMBER_OFFSET(vcpu_guest_context, ctrlreg): %ld\n",
+			ctrlreg_offset);
+
+	offset = (off_t)xd->xc_core.header.xch_ctxt_offset + 
+		(off_t)ctrlreg_offset;
+
+	if (lseek(xd->xfd, offset, SEEK_SET) == -1)
+		error(FATAL, "cannot lseek to xch_ctxt_offset\n");
+
+	if (read(xd->xfd, &ctrlreg, sizeof(ctrlreg)) !=
+	    sizeof(ctrlreg))
+		error(FATAL, "cannot read vcpu_guest_context ctrlreg[8]\n");
+
+	for (i = 0; CRASHDEBUG(1) && (i < 8); i++)
+		fprintf(xd->ofp, "ctrlreg[%d]: %lx\n", i, ctrlreg[i]);
+
+	mfn = ctrlreg[3] >> PAGESHIFT();
+
+	if (!xc_core_mfn_to_page(mfn, machdep->machspec->pml4))
+		error(FATAL, "cannot read/find cr3 page\n");
+
+	if (CRASHDEBUG(7)) 
+		x86_64_debug_dump_page(xd->ofp, machdep->machspec->pml4, 
+                	"contents of PML4 page:");
+
+	/*
+	 * kernel version <  2.6.27 => end_pfn
+	 * kernel version >= 2.6.27 => max_pfn
+	 */
+	if ((sp = symbol_search("end_pfn")))
+		kvaddr = sp->value;
+	else
+		kvaddr = symbol_value("max_pfn");
+
+	if (!x86_64_xendump_load_page(kvaddr, xd))
+		return FALSE;
+
+	up = (ulong *)(xd->page + PAGEOFFSET(kvaddr));
+	if (CRASHDEBUG(1))
+		fprintf(xd->ofp, "end pfn: %lx\n", *up);
+
+	xd->xc_core.p2m_frames = (*up/(PAGESIZE()/sizeof(ulong))) +
+                ((*up%(PAGESIZE()/sizeof(ulong))) ? 1 : 0);
+
+	if ((xd->xc_core.p2m_frame_index_list = (ulong *)
+	    malloc(xd->xc_core.p2m_frames * sizeof(ulong))) == NULL)
+        	error(FATAL, "cannot malloc p2m_frame_list");
+
+	machdep->last_ptbl_read = BADADDR;
+	kvaddr = symbol_value("p2m_top");
+
+	for (p = 0; p < xd->xc_core.p2m_frames; p += XEN_PFNS_PER_PAGE) {
+		if (!x86_64_xendump_load_page(kvaddr, xd))
+			return FALSE;
+
+		if ((idx = x86_64_xendump_page_index(kvaddr, xd)) == MFN_NOT_FOUND)
+			return FALSE;
+
+		if (CRASHDEBUG(7)) {
+ 			x86_64_debug_dump_page(xd->ofp, xd->page,
+                       		"contents of page:");
+		}
+
+		up = (ulong *)(xd->page);
+
+		for (i = 0; i < XEN_PFNS_PER_PAGE; i++, up++) {
+			if ((p+i) >= xd->xc_core.p2m_frames)
+				break;
+			if ((idx = x86_64_xendump_page_index(*up, xd)) == MFN_NOT_FOUND)
+				return FALSE;
+			xd->xc_core.p2m_frame_index_list[p+i] = idx; 
+		}
+
+		kvaddr += PAGESIZE();
+	}
+	
+	machdep->last_ptbl_read = 0;
+
+	return TRUE;
+}
+
 static void
 x86_64_debug_dump_page(FILE *ofp, char *page, char *name)
 {
--- crash-5.0.0/x86.c.orig
+++ crash-5.0.0/x86.c
@@ -995,6 +995,8 @@ static int x86_is_uvaddr(ulong, struct t
 static void x86_init_kernel_pgd(void);
 static ulong xen_m2p_nonPAE(ulong);
 static int x86_xendump_p2m_create(struct xendump_data *);
+static int x86_pvops_xendump_p2m_create(struct xendump_data *);
+static void x86_debug_dump_page(FILE *, char *, char *);
 static int x86_xen_kdump_p2m_create(struct xen_kdump_data *);
 static char *x86_xen_kdump_load_page(ulong, char *);
 static char *x86_xen_kdump_load_page_PAE(ulong, char *);
@@ -2411,7 +2413,7 @@ x86_uvtop_xen_wpt_PAE(struct task_contex
 	ulonglong page_middle, pseudo_page_middle;
 	ulonglong page_middle_entry;
 	ulonglong page_table, pseudo_page_table;
-	ulonglong page_table_entry;
+	ulonglong page_table_entry, pte;
 	ulonglong physpage, pseudo_physpage;
 	ulonglong ull;
 	ulong offset;
@@ -2568,18 +2570,19 @@ x86_uvtop_xen_wpt_PAE(struct task_contex
         *paddr = pseudo_physpage + PAGEOFFSET(vaddr);
 
         if (verbose) {
+		physpage = PAE_PAGEBASE(physpage);
                 fprintf(fp, " PAGE: %s [machine]\n", 
 			mkstring(buf, VADDR_PRLEN, RJUST|LONGLONG_HEX, 
 			MKSTR(&physpage)));
-
-                pseudo_physpage += (PAGEOFFSET(vaddr) |
-                        (page_table_entry & (_PAGE_NX|machdep->pageoffset)));
-
+		
                 fprintf(fp, " PAGE: %s\n\n",
                         mkstring(buf, VADDR_PRLEN, RJUST|LONGLONG_HEX,
                         MKSTR(&pseudo_physpage)));
 
-                x86_translate_pte(0, 0, pseudo_physpage);
+		pte = pseudo_physpage | PAGEOFFSET(page_table_entry) |
+			(page_table_entry & _PAGE_NX);
+
+                x86_translate_pte(0, 0, pte);
         }
 
         return TRUE;
@@ -2996,7 +2999,7 @@ x86_kvtop_xen_wpt_PAE(struct task_contex
         ulonglong page_middle, pseudo_page_middle;
         ulonglong page_middle_entry;
         ulonglong page_table, pseudo_page_table;
-        ulonglong page_table_entry;
+        ulonglong page_table_entry, pte;
         ulonglong physpage, pseudo_physpage;
         ulonglong ull;
         ulong offset;
@@ -3120,18 +3123,19 @@ x86_kvtop_xen_wpt_PAE(struct task_contex
         *paddr = pseudo_physpage + PAGEOFFSET(kvaddr);
 
         if (verbose) {
+		physpage = PAE_PAGEBASE(physpage);
                 fprintf(fp, " PAGE: %s [machine]\n",
                         mkstring(buf, VADDR_PRLEN, RJUST|LONGLONG_HEX,
                         MKSTR(&physpage)));
 
-		pseudo_physpage += (PAGEOFFSET(kvaddr) | 
-			(page_table_entry & _PAGE_NX));
-
                 fprintf(fp, " PAGE: %s\n\n",
                         mkstring(buf, VADDR_PRLEN, RJUST|LONGLONG_HEX,
                         MKSTR(&pseudo_physpage)));
 
-                x86_translate_pte(0, 0, pseudo_physpage);
+		pte = pseudo_physpage | PAGEOFFSET(page_table_entry) |
+			(page_table_entry & _PAGE_NX);
+
+		x86_translate_pte(0, 0, pte);
         }
 
         return TRUE;
@@ -3280,6 +3284,8 @@ x86_dump_machdep_table(ulong arg)
         fprintf(fp, "   max_physmem_bits: %ld\n", machdep->max_physmem_bits);
         fprintf(fp, "  sections_per_root: %ld\n", machdep->sections_per_root);
 	fprintf(fp, " xendump_p2m_create: x86_xendump_p2m_create()\n");
+	fprintf(fp, " xendump_p2m_create: %s\n", PVOPS_XEN() ?
+		"x86_pvops_xendump_p2m_create()" : "x86_xendump_p2m_create()");
 	fprintf(fp, " xendump_panic_task: x86_xendump_panic_task()\n");
 	fprintf(fp, "   get_xendump_regs: x86_get_xendump_regs()\n");
 	fprintf(fp, "xen_kdump_p2m_create: x86_xen_kdump_p2m_create()\n");
@@ -4150,11 +4156,14 @@ static void
 x86_init_kernel_pgd(void)
 {
         int i;
-	ulong value;
+	ulong value = 0;
 
-	if (XEN()) 
-		get_symbol_data("swapper_pg_dir", sizeof(ulong), &value);
-	else
+	if (XEN()) { 
+		if (PVOPS_XEN())
+     			value = symbol_value("swapper_pg_dir");
+		else
+			get_symbol_data("swapper_pg_dir", sizeof(ulong), &value);
+	} else
      		value = symbol_value("swapper_pg_dir");
 
        	for (i = 0; i < NR_CPUS; i++)
@@ -4530,6 +4539,13 @@ x86_xendump_p2m_create(struct xendump_da
 	ulonglong *ulp;
 	off_t offset; 
 
+	/*
+	 *  Check for pvops Xen kernel before presuming it's HVM.
+	 */
+	if (symbol_exists("pv_init_ops") && symbol_exists("xen_patch") &&
+	    (xd->xc_core.header.xch_magic == XC_CORE_MAGIC))
+		return x86_pvops_xendump_p2m_create(xd);
+
         if (!symbol_exists("phys_to_machine_mapping")) {
                 xd->flags |= XC_CORE_NO_P2M;
                 return TRUE;
@@ -4624,6 +4640,132 @@ x86_xendump_p2m_create(struct xendump_da
 	return TRUE;
 }
 
+static int 
+x86_pvops_xendump_p2m_create(struct xendump_data *xd)
+{
+	int i, p, idx;
+	ulong mfn, kvaddr, ctrlreg[8], ctrlreg_offset;
+	ulong *up;
+	ulonglong *ulp;
+	off_t offset; 
+
+	if ((ctrlreg_offset = MEMBER_OFFSET("vcpu_guest_context", "ctrlreg")) ==
+	     INVALID_OFFSET)
+		error(FATAL, 
+		    "cannot determine vcpu_guest_context.ctrlreg offset\n");
+	else if (CRASHDEBUG(1))
+		fprintf(xd->ofp, 
+		    "MEMBER_OFFSET(vcpu_guest_context, ctrlreg): %ld\n",
+			ctrlreg_offset);
+
+	offset = (off_t)xd->xc_core.header.xch_ctxt_offset + 
+		(off_t)ctrlreg_offset;
+
+	if (lseek(xd->xfd, offset, SEEK_SET) == -1)
+		error(FATAL, "cannot lseek to xch_ctxt_offset\n");
+
+	if (read(xd->xfd, &ctrlreg, sizeof(ctrlreg)) !=
+	    sizeof(ctrlreg))
+		error(FATAL, "cannot read vcpu_guest_context ctrlreg[8]\n");
+
+	mfn = (ctrlreg[3] >> PAGESHIFT()) | (ctrlreg[3] << (BITS()-PAGESHIFT()));
+
+	for (i = 0; CRASHDEBUG(1) && (i < 8); i++) {
+		fprintf(xd->ofp, "ctrlreg[%d]: %lx", i, ctrlreg[i]);
+		if (i == 3)
+			fprintf(xd->ofp, " -> mfn: %lx", mfn);
+		fprintf(xd->ofp, "\n");
+	}
+
+	if (!xc_core_mfn_to_page(mfn, machdep->pgd))
+		error(FATAL, "cannot read/find cr3 page\n");
+
+	if (CRASHDEBUG(1)) {
+		fprintf(xd->ofp, "contents of page directory page:\n");	
+
+		if (machdep->flags & PAE) {
+			ulp = (ulonglong *)machdep->pgd;
+			fprintf(xd->ofp, 
+			    "%016llx %016llx %016llx %016llx\n",
+				*ulp, *(ulp+1), *(ulp+2), *(ulp+3));
+		} else {
+			up = (ulong *)machdep->pgd;
+			for (i = 0; i < 256; i++) {
+				fprintf(xd->ofp, 
+				    "%08lx: %08lx %08lx %08lx %08lx\n", 
+					(ulong)((i * 4) * sizeof(ulong)),
+					*up, *(up+1), *(up+2), *(up+3));
+				up += 4;
+			}
+		}
+	}
+
+	kvaddr = symbol_value("max_pfn");
+	if (!x86_xendump_load_page(kvaddr, xd->page))
+		return FALSE;
+	up = (ulong *)(xd->page + PAGEOFFSET(kvaddr));
+	if (CRASHDEBUG(1))
+		fprintf(xd->ofp, "max_pfn: %lx\n", *up);
+
+        xd->xc_core.p2m_frames = (*up/(PAGESIZE()/sizeof(ulong))) +
+                ((*up%(PAGESIZE()/sizeof(ulong))) ? 1 : 0);
+
+	if ((xd->xc_core.p2m_frame_index_list = (ulong *)
+	    malloc(xd->xc_core.p2m_frames * sizeof(int))) == NULL)
+        	error(FATAL, "cannot malloc p2m_frame_index_list");
+
+	machdep->last_ptbl_read = BADADDR;
+	machdep->last_pmd_read = BADADDR;
+	kvaddr = symbol_value("p2m_top");
+
+	for (p = 0; p < xd->xc_core.p2m_frames; p += XEN_PFNS_PER_PAGE) {
+		if (!x86_xendump_load_page(kvaddr, xd->page))
+			return FALSE;
+
+		if ((idx = x86_xendump_page_index(kvaddr)) == MFN_NOT_FOUND)
+			return FALSE;
+
+		if (CRASHDEBUG(7)) {
+			x86_debug_dump_page(xd->ofp, xd->page,
+				"contents of page:");
+		}
+
+		up = (ulong *)(xd->page);
+
+		for (i = 0; i < XEN_PFNS_PER_PAGE; i++, up++) {
+			if ((p+i) >= xd->xc_core.p2m_frames)
+				break;
+			if ((idx = x86_xendump_page_index(*up)) == MFN_NOT_FOUND)
+				return FALSE;
+			xd->xc_core.p2m_frame_index_list[p+i] = idx;
+		}
+
+		kvaddr += PAGESIZE();
+        }
+
+	machdep->last_ptbl_read = 0;
+	machdep->last_pmd_read = 0;
+
+	return TRUE;
+}
+
+static void
+x86_debug_dump_page(FILE *ofp, char *page, char *name)
+{
+        int i;
+        ulong *up;
+
+        fprintf(ofp, "%s\n", name);
+
+        up = (ulong *)page;
+        for (i = 0; i < 256; i++) {
+                fprintf(ofp, "%016lx: %08lx %08lx %08lx %08lx\n",
+                        (ulong)((i * 4) * sizeof(ulong)),
+                        *up, *(up+1), *(up+2), *(up+3));
+                up += 4;
+        }
+}
+
 /*
  *  Find the page associate with the kvaddr, and read its contents
  *  into the passed-in buffer.
--- crash-5.0.0/kernel.c.orig
+++ crash-5.0.0/kernel.c
@@ -63,6 +63,7 @@ kernel_init()
 	struct syment *sp1, *sp2;
 	char *rqstruct;
 	char *irq_desc_type_name;	
+	ulong pv_init_ops;
 
 	if (pc->flags & KERNEL_DEBUG_QUERY)
 		return;
@@ -122,6 +123,26 @@ kernel_init()
                        	error(FATAL, "cannot malloc m2p page.");
 	}
 
+	if (PVOPS() && readmem(symbol_value("pv_init_ops"), KVADDR, &pv_init_ops,
+	    sizeof(void *), "pv_init_ops", RETURN_ON_ERROR) &&
+	    (p1 = value_symbol(pv_init_ops)) && 
+	    STREQ(p1, "xen_patch")) {
+		kt->flags |= ARCH_XEN | ARCH_PVOPS_XEN;
+		kt->xen_flags |= WRITABLE_PAGE_TABLES;
+		if (machine_type("X86"))
+                	get_symbol_data("max_pfn", sizeof(ulong), &kt->p2m_table_size);
+		if (machine_type("X86_64")) {
+			if (!try_get_symbol_data("end_pfn", sizeof(ulong), &kt->p2m_table_size))
+				get_symbol_data("max_pfn", sizeof(ulong), &kt->p2m_table_size);
+		}
+                if ((kt->m2p_page = (char *)malloc(PAGESIZE())) == NULL)
+                       	error(FATAL, "cannot malloc m2p page.");
+
+		kt->pvops_xen.p2m_top_entries = get_array_length("p2m_top", NULL, 0);
+		kt->pvops_xen.p2m_top = symbol_value("p2m_top");
+		kt->pvops_xen.p2m_missing = symbol_value("p2m_missing");
+	}
+
 	if (symbol_exists("smp_num_cpus")) {
 		kt->flags |= SMP;
 		get_symbol_data("smp_num_cpus", sizeof(int), &kt->cpus);
@@ -4268,6 +4289,8 @@ dump_kernel_table(int verbose)
 		fprintf(fp, "%sUSE_OLD_BT", others++ ? "|" : "");
 	if (kt->flags & ARCH_XEN)
 		fprintf(fp, "%sARCH_XEN", others++ ? "|" : "");
+	if (kt->flags & ARCH_PVOPS_XEN)
+		fprintf(fp, "%sARCH_PVOPS_XEN", others++ ? "|" : "");
 	if (kt->flags & ARCH_OPENVZ)
 		fprintf(fp, "%sARCH_OPENVZ", others++ ? "|" : "");
 	if (kt->flags & ARCH_PVOPS)
@@ -4376,7 +4399,8 @@ dump_kernel_table(int verbose)
 			LONG_PRLEN, kt->__per_cpu_offset[i]);
 		if ((i % 4) == 0) {
 			for (j = i, more = FALSE; j < nr_cpus; j++) {
-				if (kt->__per_cpu_offset[j])
+				if (kt->__per_cpu_offset[j] &&
+				    (kt->__per_cpu_offset[j] != kt->__per_cpu_offset[i]))
 					more = TRUE;
 			}
 		}
@@ -4450,8 +4474,12 @@ no_cpu_flags:
 	for (i = 0; verbose && (i < P2M_MAPPING_CACHE); i++) {
 		if (!kt->p2m_mapping_cache[i].mapping)
 			continue;
-		fprintf(fp, "       [%d] mapping: %lx start: %lx end: %lx (%ld mfns)\n",
-			i, kt->p2m_mapping_cache[i].mapping,
+		fprintf(fp, "       [%d] mapping: %lx pfn: ", i, kt->p2m_mapping_cache[i].mapping);
+		if (PVOPS_XEN())
+			fprintf(fp, "%lx ", kt->p2m_mapping_cache[i].pfn);
+		else
+			fprintf(fp, "n/a ");
+		fprintf(fp, "start: %lx end: %lx (%ld mfns)\n",
 			kt->p2m_mapping_cache[i].start,
 			kt->p2m_mapping_cache[i].end,
 			kt->p2m_mapping_cache[i].end -  kt->p2m_mapping_cache[i].start + 1);
@@ -4469,6 +4497,11 @@ no_cpu_flags:
 		fprintf(fp, "(%ld%%)\n", kt->p2m_page_cache_hits * 100 / kt->p2m_pages_searched);
 	else
 		fprintf(fp, "\n");
+
+	fprintf(fp, "              pvops_xen:\n");
+	fprintf(fp, "                    p2m_top: %lx\n", kt->pvops_xen.p2m_top);
+	fprintf(fp, "            p2m_top_entries: %d\n", kt->pvops_xen.p2m_top_entries);
+	fprintf(fp, "                p2m_missing: %lx\n", kt->pvops_xen.p2m_missing);
 }
 
 /*
@@ -6293,7 +6326,7 @@ xen_m2p(ulonglong machine)
 	if (pfn == XEN_MFN_NOT_FOUND) {
 		if (CRASHDEBUG(1))
 			error(INFO, 
-			    "xen_machine_to_pseudo_PAE: machine address %lx not found\n",
+			    "xen_m2p: machine address %lx not found\n",
                            	 machine);
 		return XEN_MACHADDR_NOT_FOUND;
 	}
@@ -6304,12 +6337,15 @@ xen_m2p(ulonglong machine)
 static ulong
 __xen_m2p(ulonglong machine, ulong mfn)
 {
-	ulong mapping, kmfn, pfn, p, i, c;
+	ulong mapping, p2m, kmfn, pfn, p, i, e, c;
 	ulong start, end;
 	ulong *mp;
 
 	mp = (ulong *)kt->m2p_page;
-	mapping = kt->phys_to_machine_mapping;
+	if (PVOPS_XEN())
+		mapping = UNINITIALIZED;
+	else
+		mapping = kt->phys_to_machine_mapping;
 
 	/*
 	 *  Check the FIFO cache first.
@@ -6333,7 +6369,7 @@ __xen_m2p(ulonglong machine, ulong mfn)
                 	for (i = 0; i < XEN_PFNS_PER_PAGE; i++) {
 				kmfn = (*(mp+i)) & ~XEN_FOREIGN_FRAME;
                         	if (kmfn == mfn) {
-					p = P2M_MAPPING_TO_PAGE_INDEX(c);
+					p = P2M_MAPPING_PAGE_PFN(c);
 					pfn = p + i;
 
                                 	if (CRASHDEBUG(1))
@@ -6353,47 +6389,100 @@ __xen_m2p(ulonglong machine, ulong mfn)
 		}
 	}
 
-	/*
-	 *  The machine address was not cached, so search from the
-	 *  beginning of the phys_to_machine_mapping array, caching
-	 *  only the found machine address.
-	 */
-	for (p = 0; p < kt->p2m_table_size; p += XEN_PFNS_PER_PAGE) 
-	{
-		if (mapping != kt->last_mapping_read) {
-			if (!readmem(mapping, KVADDR, mp, PAGESIZE(), 
-		    	    "phys_to_machine_mapping page", RETURN_ON_ERROR))
-				error(FATAL, 
-			     	    "cannot access phys_to_machine_mapping page\n");
-			else
-				kt->last_mapping_read = mapping;
-		}
-
-		kt->p2m_pages_searched++;
+	if (PVOPS_XEN()) {
+		/*
+		 *  The machine address was not cached, so search from the
+		 *  beginning of the p2m_top array, caching the contiguous
+		 *  range containing the found machine address.
+		 */
+		for (e = p = 0, p2m = kt->pvops_xen.p2m_top;
+		     e < kt->pvops_xen.p2m_top_entries; 
+		     e++, p += XEN_PFNS_PER_PAGE, p2m += sizeof(void *)) {
+
+			if (!readmem(p2m, KVADDR, &mapping,
+			    sizeof(void *), "p2m_top", RETURN_ON_ERROR))
+				error(FATAL, "cannot access p2m_top[] entry\n");
+
+			if (mapping != kt->last_mapping_read) {
+				if (mapping != kt->pvops_xen.p2m_missing) {
+					if (!readmem(mapping, KVADDR, mp, 
+					    PAGESIZE(), "p2m_top page", 
+					    RETURN_ON_ERROR))
+						error(FATAL, 
+				     	    	    "cannot access "
+						    "p2m_top[] page\n");
+					kt->last_mapping_read = mapping;
+				}
+			}
 
-		if (search_mapping_page(mfn, &i, &start, &end)) {
-			pfn = p + i;
-			if (CRASHDEBUG(1))
-			    console("pages: %d mfn: %lx (%llx) p: %ld"
-				" i: %ld pfn: %lx (%llx)\n",
-				(p/XEN_PFNS_PER_PAGE)+1, mfn, machine,
-				p, i, pfn, XEN_PFN_TO_PSEUDO(pfn));
+			if (mapping == kt->pvops_xen.p2m_missing)
+				continue;
 
-			c = kt->p2m_cache_index;
-			kt->p2m_mapping_cache[c].start = start;
-			kt->p2m_mapping_cache[c].end = end;
-			kt->p2m_mapping_cache[c].mapping = mapping;
-			kt->p2m_cache_index = (c+1) % P2M_MAPPING_CACHE;
+			kt->p2m_pages_searched++;
 
-			return pfn;
+			if (search_mapping_page(mfn, &i, &start, &end)) {
+				pfn = p + i;
+				if (CRASHDEBUG(1))
+				    console("pages: %d mfn: %lx (%llx) p: %ld"
+					" i: %ld pfn: %lx (%llx)\n",
+					(p/XEN_PFNS_PER_PAGE)+1, mfn, machine,
+					p, i, pfn, XEN_PFN_TO_PSEUDO(pfn));
+	
+				c = kt->p2m_cache_index;
+				kt->p2m_mapping_cache[c].start = start;
+				kt->p2m_mapping_cache[c].end = end;
+				kt->p2m_mapping_cache[c].mapping = mapping;
+				kt->p2m_mapping_cache[c].pfn = p;
+				kt->p2m_cache_index = (c+1) % P2M_MAPPING_CACHE;
+	
+				return pfn;
+			}
 		}
-
-		mapping += PAGESIZE();
-	}
+	} else {
+		/*
+		 *  The machine address was not cached, so search from the
+		 *  beginning of the phys_to_machine_mapping array, caching
+		 *  the contiguous range containing the found machine address.
+		 */
+		for (p = 0; p < kt->p2m_table_size; p += XEN_PFNS_PER_PAGE) 
+		{
+			if (mapping != kt->last_mapping_read) {
+				if (!readmem(mapping, KVADDR, mp, PAGESIZE(), 
+			    	    "phys_to_machine_mapping page", 
+				    RETURN_ON_ERROR))
+					error(FATAL, 
+				     	    "cannot access"
+					    " phys_to_machine_mapping page\n");
+				else
+					kt->last_mapping_read = mapping;
+			}
+	
+			kt->p2m_pages_searched++;
+	
+			if (search_mapping_page(mfn, &i, &start, &end)) {
+				pfn = p + i;
+				if (CRASHDEBUG(1))
+				    console("pages: %d mfn: %lx (%llx) p: %ld"
+					" i: %ld pfn: %lx (%llx)\n",
+					(p/XEN_PFNS_PER_PAGE)+1, mfn, machine,
+					p, i, pfn, XEN_PFN_TO_PSEUDO(pfn));
+	
+				c = kt->p2m_cache_index;
+				kt->p2m_mapping_cache[c].start = start;
+				kt->p2m_mapping_cache[c].end = end;
+				kt->p2m_mapping_cache[c].mapping = mapping;
+				kt->p2m_cache_index = (c+1) % P2M_MAPPING_CACHE;
+	
+				return pfn;
+			}
+	
+			mapping += PAGESIZE();
+		}
+	}	
 
 	if (CRASHDEBUG(1))
 		console("machine address %llx not found\n", machine);
-
+	
 	return (XEN_MFN_NOT_FOUND);
 }
 
--- crash-5.0.0/defs.h.orig
+++ crash-5.0.0/defs.h
@@ -485,12 +485,14 @@ struct new_utsname {
 #define ARCH_OPENVZ          (0x8000000)
 #define ARCH_PVOPS          (0x10000000)
 #define IN_KERNEL_INIT      (0x20000000)
+#define ARCH_PVOPS_XEN      (0x40000000)
 
 #define GCC_VERSION_DEPRECATED (GCC_3_2|GCC_3_2_3|GCC_2_96|GCC_3_3_2|GCC_3_3_3)
 
-#define XEN()    (kt->flags & ARCH_XEN)
-#define OPENVZ() (kt->flags & ARCH_OPENVZ)
-#define PVOPS()  (kt->flags & ARCH_PVOPS)
+#define XEN()       (kt->flags & ARCH_XEN)
+#define OPENVZ()    (kt->flags & ARCH_OPENVZ)
+#define PVOPS()     (kt->flags & ARCH_PVOPS)
+#define PVOPS_XEN() (kt->flags & ARCH_PVOPS_XEN)
 
 #define XEN_MACHINE_TO_MFN(m)    ((ulonglong)(m) >> PAGESHIFT())
 #define XEN_PFN_TO_PSEUDO(p)     ((ulonglong)(p) << PAGESHIFT())
@@ -543,12 +545,14 @@ struct kernel_table {                   
 #define P2M_MAPPING_CACHE    (512)
 	struct p2m_mapping_cache {
 		ulong mapping;
+		ulong pfn;
 		ulong start;
 		ulong end;
 	} p2m_mapping_cache[P2M_MAPPING_CACHE];
-#define P2M_MAPPING_TO_PAGE_INDEX(c) \
-   (((kt->p2m_mapping_cache[c].mapping - kt->phys_to_machine_mapping)/PAGESIZE()) \
-    * XEN_PFNS_PER_PAGE)
+#define P2M_MAPPING_PAGE_PFN(c) \
+   (PVOPS_XEN() ? kt->p2m_mapping_cache[c].pfn : \
+    (((kt->p2m_mapping_cache[c].mapping - kt->phys_to_machine_mapping)/PAGESIZE()) \
+    * XEN_PFNS_PER_PAGE))
 	ulong last_mapping_read;
 	ulong p2m_cache_index;
 	ulong p2m_pages_searched;
@@ -556,6 +560,11 @@ struct kernel_table {                   
 	ulong p2m_page_cache_hits;
 	ulong relocate;
 	char *module_tree;
+	struct pvops_xen_info {
+		int p2m_top_entries;
+		ulong p2m_top;
+		ulong p2m_missing;
+	} pvops_xen;
 };
 
 /*
